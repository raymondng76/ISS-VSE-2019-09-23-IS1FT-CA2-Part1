{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ISS VSE CA2 Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### By: Kenneth Goh (A0198544N), Raymond Ng (A0198543R), Tan Heng Han (A0198502B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "import cv2\n",
    "from time import time\n",
    "from math import exp as exp\n",
    "\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('C:\\Program Files (x86)\\IntelSWTools\\openvino_2019.2.275\\python\\python3.6')\n",
    "\n",
    "try:\n",
    "    from openvino import inference_engine as ie\n",
    "    from openvino.inference_engine import IENetwork, IECore\n",
    "except Exception as e:\n",
    "    exception_type = type(e).__name__\n",
    "    print(\"The following error happened while importing Python API module:\\n[ {} ] {}\".format(exception_type, e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to change device type here\n",
    "# deviceType = 'CPU' # This is using CPU\n",
    "deviceType = 'GPU' # This is using GPU\n",
    "# deviceType = 'MYRIAD' # This is using NCS for inferencing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Methods for YOLOv3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \\\n",
    "              \"boat\", \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \\\n",
    "              \"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \\\n",
    "              \"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \\\n",
    "              \"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\", \\\n",
    "              \"tennis racket\", \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \\\n",
    "              \"apple\", \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \\\n",
    "              \"chair\", \"sofa\", \"pottedplant\", \"bed\", \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \\\n",
    "              \"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \\\n",
    "              \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YoloV3Params:\n",
    "    def __init__(self, param, side):\n",
    "        self.num = 3 if 'num' not in param else int(param['num'])\n",
    "        self.coords = 4 if 'coords' not in param else int(param['coords'])\n",
    "        self.classes = 80 if 'classes' not in param else int(param['classes'])\n",
    "        self.anchors = [10.0, 13.0, 16.0, 30.0, 33.0, 23.0, 30.0, 61.0, 62.0, 45.0, 59.0, 119.0, 116.0, 90.0, 156.0,\n",
    "                        198.0,\n",
    "                        373.0, 326.0] if 'anchors' not in param else [float(a) for a in param['anchors'].split(',')]\n",
    "\n",
    "        if 'mask' in param:\n",
    "            mask = [int(idx) for idx in param['mask'].split(',')]\n",
    "            self.num = len(mask)\n",
    "\n",
    "            maskedAnchors = []\n",
    "            for idx in mask:\n",
    "                maskedAnchors += [self.anchors[idx * 2], self.anchors[idx * 2 + 1]]\n",
    "            self.anchors = maskedAnchors\n",
    "\n",
    "        self.side = side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entry_index(side, coord, classes, location, entry):\n",
    "    side_power_2 = side ** 2\n",
    "    n = location // side_power_2\n",
    "    loc = location % side_power_2\n",
    "    return int(side_power_2 * (n * (coord + classes + 1) + entry) + loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_bbox(x, y, h, w, class_id, confidence, h_scale, w_scale):\n",
    "    xmin = int((x - w / 2) * w_scale)\n",
    "    ymin = int((y - h / 2) * h_scale)\n",
    "    xmax = int(xmin + w * w_scale)\n",
    "    ymax = int(ymin + h * h_scale)\n",
    "    return dict(xmin=xmin, xmax=xmax, ymin=ymin, ymax=ymax, class_id=class_id, confidence=confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection_over_union(box_1, box_2):\n",
    "    width_of_overlap_area = min(box_1['xmax'], box_2['xmax']) - max(box_1['xmin'], box_2['xmin'])\n",
    "    height_of_overlap_area = min(box_1['ymax'], box_2['ymax']) - max(box_1['ymin'], box_2['ymin'])\n",
    "    if width_of_overlap_area < 0 or height_of_overlap_area < 0:\n",
    "        area_of_overlap = 0\n",
    "    else:\n",
    "        area_of_overlap = width_of_overlap_area * height_of_overlap_area\n",
    "    box_1_area = (box_1['ymax'] - box_1['ymin']) * (box_1['xmax'] - box_1['xmin'])\n",
    "    box_2_area = (box_2['ymax'] - box_2['ymin']) * (box_2['xmax'] - box_2['xmin'])\n",
    "    area_of_union = box_1_area + box_2_area - area_of_overlap\n",
    "    if area_of_union == 0:\n",
    "        return 0\n",
    "    return area_of_overlap / area_of_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_yolo_region(blob, resized_image_shape, original_im_shape, params, threshold):\n",
    "    _, _, out_blob_h, out_blob_w = blob.shape\n",
    "    assert out_blob_w == out_blob_h, \"Invalid size of output blob. It sould be in NCHW layout and height should \" \\\n",
    "                                     \"be equal to width. Current height = {}, current width = {}\" \\\n",
    "                                     \"\".format(out_blob_h, out_blob_w)\n",
    "\n",
    "    orig_im_h, orig_im_w = original_im_shape\n",
    "    resized_image_h, resized_image_w = resized_image_shape\n",
    "    objects = list()\n",
    "    predictions = blob.flatten()\n",
    "    side_square = params.side * params.side\n",
    "\n",
    "    for i in range(side_square):\n",
    "        row = i // params.side\n",
    "        col = i % params.side\n",
    "        for n in range(params.num):\n",
    "            obj_index = entry_index(params.side, params.coords, params.classes, n * side_square + i, params.coords)\n",
    "            scale = predictions[obj_index]\n",
    "            if scale < threshold:\n",
    "                continue\n",
    "            box_index = entry_index(params.side, params.coords, params.classes, n * side_square + i, 0)\n",
    "            x = (col + predictions[box_index + 0 * side_square]) / params.side * resized_image_w\n",
    "            y = (row + predictions[box_index + 1 * side_square]) / params.side * resized_image_h\n",
    "            # Value for exp is very big number in some cases so following construction is using here\n",
    "            try:\n",
    "                w_exp = exp(predictions[box_index + 2 * side_square])\n",
    "                h_exp = exp(predictions[box_index + 3 * side_square])\n",
    "            except OverflowError:\n",
    "                continue\n",
    "            w = w_exp * params.anchors[2 * n]\n",
    "            h = h_exp * params.anchors[2 * n + 1]\n",
    "            for j in range(params.classes):\n",
    "                class_index = entry_index(params.side, params.coords, params.classes, n * side_square + i,\n",
    "                                          params.coords + 1 + j)\n",
    "                confidence = scale * predictions[class_index]\n",
    "                if confidence < threshold:\n",
    "                    continue\n",
    "                objects.append(scale_bbox(x=x, y=y, h=h, w=w, class_id=j, confidence=confidence,\n",
    "                                          h_scale=orig_im_h / resized_image_h, w_scale=orig_im_w / resized_image_w))\n",
    "    return objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Yolov3 Tensorflow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pb_file = './model/Full_yolov3_model.pb'\n",
    "json_file = './model/yolo_v3.json'\n",
    "output_dir = './model'\n",
    "cpu_ext = 'C:\\\\Users\\\\raymo\\\\Documents\\\\Intel\\\\OpenVINO\\\\inference_engine_samples_build\\\\intel64\\\\Release\\\\cpu_extension.dll'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mo_tf_path = '\"C:\\Program Files (x86)\\IntelSWTools\\openvino\\deployment_tools\\model_optimizer\\mo_tf.py\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Optimizer arguments:\n",
      "Common parameters:\n",
      "\t- Path to the Input Model: \tD:\\Workspace\\GitHub\\ISS-VSE-2019-09-23-IS1FT-CA2-Part1\\./model/Full_yolov3_model.pb\n",
      "\t- Path for generated IR: \tD:\\Workspace\\GitHub\\ISS-VSE-2019-09-23-IS1FT-CA2-Part1\\./model\n",
      "\t- IR output name: \tFull_yolov3_model\n",
      "\t- Log level: \tERROR\n",
      "\t- Batch: \t1\n",
      "\t- Input layers: \tNot specified, inherited from the model\n",
      "\t- Output layers: \tNot specified, inherited from the model\n",
      "\t- Input shapes: \tNot specified, inherited from the model\n",
      "\t- Mean values: \tNot specified\n",
      "\t- Scale values: \tNot specified\n",
      "\t- Scale factor: \tNot specified\n",
      "\t- Precision of IR: \tFP16\n",
      "\t- Enable fusing: \tTrue\n",
      "\t- Enable grouped convolutions fusing: \tTrue\n",
      "\t- Move mean values to preprocess section: \tFalse\n",
      "\t- Reverse input channels: \tFalse\n",
      "TensorFlow specific parameters:\n",
      "\t- Input model in text protobuf format: \tFalse\n",
      "\t- Path to model dump for TensorBoard: \tNone\n",
      "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
      "\t- Update the configuration file with input/output node names: \tNone\n",
      "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
      "\t- Operations to offload: \tNone\n",
      "\t- Patterns to offload: \tNone\n",
      "\t- Use the config file: \tD:\\Workspace\\GitHub\\ISS-VSE-2019-09-23-IS1FT-CA2-Part1\\./model/yolo_v3.json\n",
      "Model Optimizer version: \t2019.2.0-436-gf5827d4\n",
      "WARNING:tensorflow:From C:\\Program Files (x86)\\IntelSWTools\\openvino\\deployment_tools\\model_optimizer\\mo\\front\\tf\\partial_infer\\tf.py:148: The name tf.NodeDef is deprecated. Please use tf.compat.v1.NodeDef instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARNING ]  From %s: The name %s is deprecated. Please use %s instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Program Files (x86)\\IntelSWTools\\openvino\\deployment_tools\\model_optimizer\\mo\\front\\tf\\loader.py:35: The name tf.GraphDef is deprecated. Please use tf.compat.v1.GraphDef instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARNING ]  From %s: The name %s is deprecated. Please use %s instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Program Files (x86)\\IntelSWTools\\openvino\\deployment_tools\\model_optimizer\\mo\\front\\tf\\loader.py:109: The name tf.MetaGraphDef is deprecated. Please use tf.compat.v1.MetaGraphDef instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARNING ]  From %s: The name %s is deprecated. Please use %s instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ SUCCESS ] Generated IR model.\n",
      "[ SUCCESS ] XML file: D:\\Workspace\\GitHub\\ISS-VSE-2019-09-23-IS1FT-CA2-Part1\\./model\\Full_yolov3_model.xml\n",
      "[ SUCCESS ] BIN file: D:\\Workspace\\GitHub\\ISS-VSE-2019-09-23-IS1FT-CA2-Part1\\./model\\Full_yolov3_model.bin\n",
      "[ SUCCESS ] Total execution time: 24.87 seconds. \n"
     ]
    }
   ],
   "source": [
    "# Change data_type tuo FP32 if deviceType is CPU, else change data_type to FP16 if deviceType is GPU or MYRIAD (NCS)\n",
    "if deviceType == 'CPU':\n",
    "    %run -i {mo_tf_path} --input_model {pb_file} --output_dir {output_dir} --tensorflow_use_custom_operations_config {json_file} --batch 1 --data_type FP32\n",
    "else:\n",
    "    %run -i {mo_tf_path} --input_model {pb_file} --output_dir {output_dir} --tensorflow_use_custom_operations_config {json_file} --batch 1 --data_type FP16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create OpenVino network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xml = './model/Full_yolov3_model.xml'\n",
    "model_bin = './model/Full_yolov3_model.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ie = IECore()\n",
    "if deviceType == 'CPU':\n",
    "    ie.add_extension(cpu_ext, \"CPU\")\n",
    "    \n",
    "network = IENetwork(\n",
    "    model=model_xml,\n",
    "    weights=model_bin)\n",
    "\n",
    "network.batch_size = 1\n",
    "\n",
    "iBlob = next(iter(network.inputs))\n",
    "n, c, h, w = network.inputs[iBlob].shape\n",
    "\n",
    "exec_net = ie.load_network(\n",
    "    network=network,\n",
    "    num_requests=2,\n",
    "    device_name=deviceType) # Change device type at top of notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_threshold = 0.5\n",
    "iou_threshold = 0.4\n",
    "labels_map = None\n",
    "render_time = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Video Inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid = cv2.VideoCapture(0)\n",
    "# Start live video and inferencing\n",
    "while vid.isOpened():\n",
    "    ret, frame = vid.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    in_frame = cv2.resize(frame, (w, h))\n",
    "    in_frame = in_frame.transpose((2, 0 ,1))\n",
    "    in_frame = in_frame.reshape((n, c, h, w))\n",
    "    \n",
    "    # This code is to start inferencing\n",
    "    infer_start = time()\n",
    "    exec_net.start_async(\n",
    "        request_id=0, #ASync mode\n",
    "        inputs={iBlob: in_frame})\n",
    "    \n",
    "    objects = []\n",
    "    if exec_net.requests[0].wait(-1) == 0:\n",
    "        output = exec_net.requests[0].outputs\n",
    "    \n",
    "        for layer_name, oBlob in output.items():\n",
    "            layers_params = YoloV3Params(\n",
    "                network.layers[layer_name].params,\n",
    "                oBlob.shape[2])\n",
    "            objects += parse_yolo_region(\n",
    "                oBlob,\n",
    "                in_frame.shape[2:],\n",
    "                frame.shape[:-1],\n",
    "                layers_params,\n",
    "                probability_threshold)\n",
    "        det_time = time() - infer_start\n",
    "        \n",
    "    objects = sorted(objects, key=lambda obj: obj['confidence'], reverse=True)\n",
    "    for i in range(len(objects)):\n",
    "        if objects[i]['confidence'] == 0:\n",
    "            continue\n",
    "        for j in range(i + 1, len(objects)):\n",
    "            if intersection_over_union(objects[i], objects[j]) > iou_threshold:\n",
    "                objects[j]['confidence'] = 0\n",
    "    \n",
    "    objects = [obj for obj in objects if obj['confidence'] >= probability_threshold]\n",
    "    \n",
    "    org_img_size = frame.shape[:-1]\n",
    "    \n",
    "    for obj in objects:\n",
    "        if obj['xmax'] > org_img_size[1] or obj['ymax'] > org_img_size[0] or obj['xmin'] < 0 or obj['ymin'] < 0:\n",
    "            continue\n",
    "        color = (int(min(obj['class_id'] * 10, 255)),\n",
    "                min(obj['class_id'] * 5, 255),\n",
    "                min(obj['class_id'] * 3, 255))\n",
    "        det_label = obj['class_id']\n",
    "        \n",
    "        cv2.rectangle(frame, (obj['xmin'], obj['ymin'], obj['xmax'], obj['ymax']), color, 2)\n",
    "        cv2.putText(frame, str(labels[int(det_label)]), (obj['xmin'], obj['ymin'] - 7), cv2.FONT_HERSHEY_COMPLEX, 1, (212,175,55), 1)\n",
    "    \n",
    "    det_msg = f\"{deviceType} Detection Speed: {(render_time * 1000) :.3f}ms\"\n",
    "    cv2.putText(frame, det_msg, (15, 15), cv2.FONT_HERSHEY_COMPLEX, 0.5, (255,223,1), 1)\n",
    "    \n",
    "    cv2.imshow(\"Results\", frame)\n",
    "    render_time = time() - infer_start\n",
    "    \n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "vid.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
