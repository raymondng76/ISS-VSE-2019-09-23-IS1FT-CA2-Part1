{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('C:\\Program Files (x86)\\IntelSWTools\\openvino_2019.2.275\\python\\python3.6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[1,416,416,3]'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pb_file = './model/frozen_darknet_yolov3_model.pb'\n",
    "output_dir = './model'\n",
    "img_height = 416\n",
    "input_shape = [1,img_height,img_height,3]\n",
    "input_shape_str = str(input_shape).replace(' ','')\n",
    "input_shape_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mo_tf_path = '\"C:\\Program Files (x86)\\IntelSWTools\\openvino\\deployment_tools\\model_optimizer\\mo_tf.py\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Optimizer arguments:\n",
      "Common parameters:\n",
      "\t- Path to the Input Model: \tD:\\Workspace\\GitHub\\ISS-VSE-2019-09-23-IS1FT-CA2-Part1\\./model/frozen_darknet_yolov3_model.pb\n",
      "\t- Path for generated IR: \tD:\\Workspace\\GitHub\\ISS-VSE-2019-09-23-IS1FT-CA2-Part1\\./model\n",
      "\t- IR output name: \tfrozen_darknet_yolov3_model\n",
      "\t- Log level: \tERROR\n",
      "\t- Batch: \tNot specified, inherited from the model\n",
      "\t- Input layers: \tNot specified, inherited from the model\n",
      "\t- Output layers: \tNot specified, inherited from the model\n",
      "\t- Input shapes: \t[1,416,416,3]\n",
      "\t- Mean values: \tNot specified\n",
      "\t- Scale values: \tNot specified\n",
      "\t- Scale factor: \tNot specified\n",
      "\t- Precision of IR: \tFP16\n",
      "\t- Enable fusing: \tTrue\n",
      "\t- Enable grouped convolutions fusing: \tTrue\n",
      "\t- Move mean values to preprocess section: \tFalse\n",
      "\t- Reverse input channels: \tFalse\n",
      "TensorFlow specific parameters:\n",
      "\t- Input model in text protobuf format: \tFalse\n",
      "\t- Path to model dump for TensorBoard: \tNone\n",
      "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
      "\t- Update the configuration file with input/output node names: \tNone\n",
      "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
      "\t- Operations to offload: \tNone\n",
      "\t- Patterns to offload: \tNone\n",
      "\t- Use the config file: \tNone\n",
      "Model Optimizer version: \t2019.2.0-436-gf5827d4\n",
      "\n",
      "[ SUCCESS ] Generated IR model.\n",
      "[ SUCCESS ] XML file: D:\\Workspace\\GitHub\\ISS-VSE-2019-09-23-IS1FT-CA2-Part1\\./model\\frozen_darknet_yolov3_model.xml\n",
      "[ SUCCESS ] BIN file: D:\\Workspace\\GitHub\\ISS-VSE-2019-09-23-IS1FT-CA2-Part1\\./model\\frozen_darknet_yolov3_model.bin\n",
      "[ SUCCESS ] Total execution time: 22.79 seconds. \n"
     ]
    }
   ],
   "source": [
    "%run -i {mo_tf_path} --input_model {pb_file} --output_dir {output_dir} --input_shape {input_shape_str} --data_type FP16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from openvino import inference_engine as ie\n",
    "    from openvino.inference_engine import IENetwork, IEPlugin\n",
    "except Exception as e:\n",
    "    exception_type = type(e).__name__\n",
    "    print(\"The following error happened while importing Python API module:\\n[ {} ] {}\".format(exception_type, e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[VPU] Cannot convert layer \"detector/yolo-v3/Exp_2\" due to unsupported layer type \"exp\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mC:\\Program Files (x86)\\IntelSWTools\\openvino\\deployment_tools\\model_optimizer\\mo_tf.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mout_blob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# Load network to the plugin\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mexec_net\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplugin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;32mdel\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mie_api.pyx\u001b[0m in \u001b[0;36mopenvino.inference_engine.ie_api.IEPlugin.load\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mie_api.pyx\u001b[0m in \u001b[0;36mopenvino.inference_engine.ie_api.IEPlugin.load\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [VPU] Cannot convert layer \"detector/yolo-v3/Exp_2\" due to unsupported layer type \"exp\""
     ]
    }
   ],
   "source": [
    "# Plugin initialization for specified device and load extensions library if specified.\n",
    "plugin_dir = None\n",
    "model_xml = './model/frozen_darknet_yolov3_model.xml'\n",
    "model_bin = './model/frozen_darknet_yolov3_model.bin'\n",
    "# Devices: GPU (intel), CPU, MYRIAD\n",
    "plugin = IEPlugin(\"MYRIAD\", plugin_dirs=plugin_dir)\n",
    "# Read IR\n",
    "net = IENetwork(model=model_xml, weights=model_bin)\n",
    "assert len(net.inputs.keys()) == 1\n",
    "assert len(net.outputs) == 1\n",
    "input_blob = next(iter(net.inputs))\n",
    "out_blob = next(iter(net.outputs))\n",
    "# Load network to the plugin\n",
    "exec_net = plugin.load(network=net)\n",
    "del net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
