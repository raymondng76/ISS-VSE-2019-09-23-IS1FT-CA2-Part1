{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "import cv2\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('C:\\Program Files (x86)\\IntelSWTools\\openvino_2019.2.275\\python\\python3.6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[1,28,28,1]'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pb_file = './model/tf_model.pb'\n",
    "output_dir = './model'\n",
    "img_height = 28\n",
    "input_shape = [1, img_height,img_height,1]\n",
    "input_shape_str = str(input_shape).replace(' ','')\n",
    "input_shape_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "mo_tf_path = '\"C:\\Program Files (x86)\\IntelSWTools\\openvino\\deployment_tools\\model_optimizer\\mo_tf.py\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Optimizer arguments:\n",
      "Common parameters:\n",
      "\t- Path to the Input Model: \tD:\\Workspace\\GitHub\\ISS-VSE-2019-09-23-IS1FT-CA2-Part1\\./model/tf_model.pb\n",
      "\t- Path for generated IR: \tD:\\Workspace\\GitHub\\ISS-VSE-2019-09-23-IS1FT-CA2-Part1\\./model\n",
      "\t- IR output name: \ttf_model\n",
      "\t- Log level: \tERROR\n",
      "\t- Batch: \tNot specified, inherited from the model\n",
      "\t- Input layers: \tNot specified, inherited from the model\n",
      "\t- Output layers: \tNot specified, inherited from the model\n",
      "\t- Input shapes: \t[1,28,28,1]\n",
      "\t- Mean values: \tNot specified\n",
      "\t- Scale values: \tNot specified\n",
      "\t- Scale factor: \tNot specified\n",
      "\t- Precision of IR: \tFP16\n",
      "\t- Enable fusing: \tTrue\n",
      "\t- Enable grouped convolutions fusing: \tTrue\n",
      "\t- Move mean values to preprocess section: \tFalse\n",
      "\t- Reverse input channels: \tFalse\n",
      "TensorFlow specific parameters:\n",
      "\t- Input model in text protobuf format: \tFalse\n",
      "\t- Path to model dump for TensorBoard: \tNone\n",
      "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
      "\t- Update the configuration file with input/output node names: \tNone\n",
      "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
      "\t- Operations to offload: \tNone\n",
      "\t- Patterns to offload: \tNone\n",
      "\t- Use the config file: \tNone\n",
      "Model Optimizer version: \t2019.2.0-436-gf5827d4\n",
      "\n",
      "[ SUCCESS ] Generated IR model.\n",
      "[ SUCCESS ] XML file: D:\\Workspace\\GitHub\\ISS-VSE-2019-09-23-IS1FT-CA2-Part1\\./model\\tf_model.xml\n",
      "[ SUCCESS ] BIN file: D:\\Workspace\\GitHub\\ISS-VSE-2019-09-23-IS1FT-CA2-Part1\\./model\\tf_model.bin\n",
      "[ SUCCESS ] Total execution time: 1.03 seconds. \n"
     ]
    }
   ],
   "source": [
    "%run -i {mo_tf_path} --input_model {pb_file} --output_dir {output_dir} --input_shape {input_shape_str} --data_type FP16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from openvino import inference_engine as ie\n",
    "    from openvino.inference_engine import IENetwork, IEPlugin\n",
    "except Exception as e:\n",
    "    exception_type = type(e).__name__\n",
    "    print(\"The following error happened while importing Python API module:\\n[ {} ] {}\".format(exception_type, e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plugin initialization for specified device and load extensions library if specified.\n",
    "plugin_dir = None\n",
    "model_xml = './model/tf_model.xml'\n",
    "model_bin = './model/tf_model.bin'\n",
    "# Devices: GPU (intel), CPU, MYRIAD\n",
    "plugin = IEPlugin(\"GPU\", plugin_dirs=plugin_dir)\n",
    "# Read IR\n",
    "net = IENetwork(model=model_xml, weights=model_bin)\n",
    "assert len(net.inputs.keys()) == 1\n",
    "assert len(net.outputs) == 1\n",
    "input_blob = next(iter(net.inputs))\n",
    "out_blob = next(iter(net.outputs))\n",
    "# Load network to the plugin\n",
    "exec_net = plugin.load(network=net)\n",
    "del net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_image(imagePath, img_height=28):\n",
    "    # Model input format\n",
    "    n, c, h, w = [1, 1, img_height, img_height]\n",
    "    image = Image.open(imagePath)\n",
    "    processedImg = image.resize((h, w), resample=Image.BILINEAR)\n",
    "\n",
    "    # Normalize to keep data between 0 - 1\n",
    "    processedImg = (np.array(processedImg) - 0) / 255.0\n",
    "\n",
    "    # Change data layout from HWC to CHW\n",
    "    processedImg = processedImg.transpose((2, 0, 1))\n",
    "    processedImg = processedImg.reshape((n, c, h, w))\n",
    "\n",
    "    return image, processedImg, imagePath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PngImageFile' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mC:\\Program Files (x86)\\IntelSWTools\\openvino\\deployment_tools\\model_optimizer\\mo_tf.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'unnamed-chunk-60-1.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'PngImageFile' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "image = Image.open('unnamed-chunk-60-1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 3136 into shape (1,3,28,28)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Program Files (x86)\\IntelSWTools\\openvino\\deployment_tools\\model_optimizer\\mo_tf.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mfileName\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'unnamed-chunk-60-1.png'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# image = Image.open(imagePath)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprocessedImg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimagePath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpre_process_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileName\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mexec_net\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0minput_blob\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mprocessedImg\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexec_net\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0minput_blob\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mprocessedImg\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\IntelSWTools\\openvino\\deployment_tools\\model_optimizer\\mo_tf.py\u001b[0m in \u001b[0;36mpre_process_image\u001b[1;34m(imagePath, img_height)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m# Change data layout from HWC to CHW\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mprocessedImg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprocessedImg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mprocessedImg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprocessedImg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprocessedImg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimagePath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 3136 into shape (1,3,28,28)"
     ]
    }
   ],
   "source": [
    "# Run inference\n",
    "fileName = 'unnamed-chunk-60-1.png'\n",
    "# image = Image.open(imagePath)\n",
    "image, processedImg, imagePath = pre_process_image(fileName)\n",
    "exec_net.start_async(request_id=0, inputs={input_blob: processedImg})\n",
    "res = exec_net.infer(inputs={input_blob: processedImg})\n",
    "# Access the results and get the index of the highest confidence score\n",
    "output_node_name = list(res.keys())[0]\n",
    "res = res[output_node_name]\n",
    "# idx = np.argsort(res[0])[-1]\n",
    "# idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'openvino.inference_engine.ie_api.ExecutableNetwork' object has no attribute 'layers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mC:\\Program Files (x86)\\IntelSWTools\\openvino\\deployment_tools\\model_optimizer\\mo_tf.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexec_net\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequests\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mlayer_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_blob\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m             \u001b[0mlayer_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mYoloV3Params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexec_net\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlayer_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_blob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m             \u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Layer {} parameters: \"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[0mlayer_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'openvino.inference_engine.ie_api.ExecutableNetwork' object has no attribute 'layers'"
     ]
    }
   ],
   "source": [
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    in_frame = cv2.resize(frame, (416, 416))\n",
    "    in_frame = in_frame.transpose((2, 0, 1))  # Change data layout from HWC to CHW\n",
    "    in_frame = in_frame.reshape((1, 3, 416, 416))\n",
    "    exec_net.start_async(request_id=0, inputs={input_blob: in_frame})\n",
    "    objects = list()\n",
    "    if exec_net.requests[0].wait(-1) == 0:\n",
    "        output = exec_net.requests[0].outputs\n",
    "        for layer_name, out_blob in output.items():\n",
    "            layer_params = YoloV3Params(exec_net.layers[layer_name].params, out_blob.shape[2])\n",
    "            log.info(\"Layer {} parameters: \".format(layer_name))\n",
    "            layer_params.log_params()\n",
    "            print(out_blob.shape)\n",
    "            objects += parse_yolo_region(out_blob, in_frame.shape[2:],\n",
    "                                         frame.shape[:-1], layer_params,\n",
    "                                         args.prob_threshold)\n",
    "    objects = sorted(objects, key=lambda obj : obj['confidence'], reverse=True)\n",
    "    for i in range(len(objects)):\n",
    "        if objects[i]['confidence'] == 0:\n",
    "            continue\n",
    "        for j in range(i + 1, len(objects)):\n",
    "            if intersection_over_union(objects[i], objects[j]) > args.iou_threshold:\n",
    "                objects[j]['confidence'] = 0\n",
    "\n",
    "    # Drawing objects with respect to the --prob_threshold CLI parameter\n",
    "    objects = [obj for obj in objects if obj['confidence'] >= args.prob_threshold]\n",
    "\n",
    "    if len(objects) and args.raw_output_message:\n",
    "        log.info(\"\\nDetected boxes for batch {}:\".format(1))\n",
    "        log.info(\" Class ID | Confidence | XMIN | YMIN | XMAX | YMAX | COLOR \")\n",
    "\n",
    "    origin_im_size = frame.shape[:-1]\n",
    "    for obj in objects:\n",
    "        # Validation bbox of detected object\n",
    "        if obj['xmax'] > origin_im_size[1] or obj['ymax'] > origin_im_size[0] or obj['xmin'] < 0 or obj['ymin'] < 0:\n",
    "            continue\n",
    "        color = (int(min(obj['class_id'] * 12.5, 255)),\n",
    "                 min(obj['class_id'] * 7, 255), min(obj['class_id'] * 5, 255))\n",
    "        det_label = labels_map[obj['class_id']] if labels_map and len(labels_map) >= obj['class_id'] else \\\n",
    "            str(obj['class_id'])\n",
    "\n",
    "        if args.raw_output_message:\n",
    "            log.info(\n",
    "                \"{:^9} | {:10f} | {:4} | {:4} | {:4} | {:4} | {} \".format(det_label, obj['confidence'], obj['xmin'],\n",
    "                                                                          obj['ymin'], obj['xmax'], obj['ymax'],\n",
    "                                                                          color))\n",
    "\n",
    "        cv2.rectangle(frame, (obj['xmin'], obj['ymin']), (obj['xmax'], obj['ymax']), color, 2)\n",
    "        cv2.putText(frame,\n",
    "                    \"#\" + det_label + ' ' + str(round(obj['confidence'] * 100, 1)) + ' %',\n",
    "                    (obj['xmin'], obj['ymin'] - 7), cv2.FONT_HERSHEY_COMPLEX, 0.6, color, 1)\n",
    "        cv2.imshow(\"DetectionResults\", frame)\n",
    "\n",
    "        key = cv2.waitKey(wait_key_code)\n",
    "\n",
    "        # ESC key\n",
    "        if key == 27:\n",
    "            break\n",
    "\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\rtav\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARNING ]  From %s: The name %s is deprecated. Please use %s instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\rtav\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\IntelSWTools\\openvino\\deployment_tools\\model_optimizer\\mo_tf.py:38: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(28, 28, 1..., activation=\"relu\")`\n",
      "[ WARNING ]  From %s: The name %s is deprecated. Please use %s instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\rtav\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARNING ]  From %s: The name %s is deprecated. Please use %s instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\rtav\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\IntelSWTools\\openvino\\deployment_tools\\model_optimizer\\mo_tf.py:41: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
      "C:\\Program Files (x86)\\IntelSWTools\\openvino\\deployment_tools\\model_optimizer\\mo_tf.py:42: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
      "[ WARNING ]  From %s: calling %s (from %s) with %s is deprecated and will be removed %s.\n",
      "Instructions for updating:\n",
      "%s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 11, 11, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 9, 9, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 85,770\n",
      "Trainable params: 85,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\rtav\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARNING ]  From %s: The name %s is deprecated. Please use %s instead.\n",
      "\n",
      "C:\\Program Files (x86)\\IntelSWTools\\openvino\\deployment_tools\\model_optimizer\\mo_tf.py:56: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\rtav\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARNING ]  From %s: %s (from %s) is deprecated and will be removed %s.\n",
      "Instructions for updating:\n",
      "%s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 23s 386us/step - loss: 0.2634 - acc: 0.9170 - val_loss: 0.0623 - val_acc: 0.9804\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 21s 351us/step - loss: 0.0914 - acc: 0.9730 - val_loss: 0.0386 - val_acc: 0.9870\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 20s 334us/step - loss: 0.0662 - acc: 0.9803 - val_loss: 0.0291 - val_acc: 0.9899\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 20s 331us/step - loss: 0.0523 - acc: 0.9841 - val_loss: 0.0272 - val_acc: 0.9913\n",
      "Epoch 5/15\n",
      "60000/60000 [==============================] - 21s 355us/step - loss: 0.0442 - acc: 0.9861 - val_loss: 0.0274 - val_acc: 0.9909\n",
      "Epoch 6/15\n",
      "60000/60000 [==============================] - 19s 322us/step - loss: 0.0371 - acc: 0.9884 - val_loss: 0.0259 - val_acc: 0.9925\n",
      "Epoch 7/15\n",
      "60000/60000 [==============================] - 20s 331us/step - loss: 0.0331 - acc: 0.9897 - val_loss: 0.0256 - val_acc: 0.9917\n",
      "Epoch 8/15\n",
      "60000/60000 [==============================] - 20s 330us/step - loss: 0.0303 - acc: 0.9908 - val_loss: 0.0371 - val_acc: 0.9888\n",
      "Epoch 9/15\n",
      "60000/60000 [==============================] - 21s 352us/step - loss: 0.0264 - acc: 0.9917 - val_loss: 0.0264 - val_acc: 0.9923\n",
      "Epoch 10/15\n",
      "60000/60000 [==============================] - 22s 359us/step - loss: 0.0244 - acc: 0.9922 - val_loss: 0.0275 - val_acc: 0.9918\n",
      "Epoch 11/15\n",
      "60000/60000 [==============================] - 22s 360us/step - loss: 0.0237 - acc: 0.9924 - val_loss: 0.0245 - val_acc: 0.9927\n",
      "Epoch 12/15\n",
      "60000/60000 [==============================] - 21s 355us/step - loss: 0.0194 - acc: 0.9936 - val_loss: 0.0260 - val_acc: 0.9929\n",
      "Epoch 13/15\n",
      "60000/60000 [==============================] - 22s 359us/step - loss: 0.0193 - acc: 0.9937 - val_loss: 0.0255 - val_acc: 0.9927\n",
      "Epoch 14/15\n",
      "60000/60000 [==============================] - 21s 358us/step - loss: 0.0174 - acc: 0.9945 - val_loss: 0.0223 - val_acc: 0.9938\n",
      "Epoch 15/15\n",
      "60000/60000 [==============================] - 21s 354us/step - loss: 0.0163 - acc: 0.9947 - val_loss: 0.0240 - val_acc: 0.9926\n"
     ]
    }
   ],
   "source": [
    "#%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Convolution2D, MaxPooling2D, Flatten\n",
    "from keras.optimizers import adam\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import backend as K\n",
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "x_train = x_train/255\n",
    "x_test = x_test/255\n",
    "\n",
    "y_dummy_train = to_categorical(y_train)\n",
    "y_dummy_test = to_categorical(y_test)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(32, 3, 3, input_shape = input_shape, activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Convolution2D(32, 3, 3, activation=\"relu\"))\n",
    "model.add(Convolution2D(32, 3, 3, activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "\n",
    "\n",
    "hist = model.fit(x_train, y_dummy_train,\n",
    "                 validation_data = (x_test, y_dummy_test), nb_epoch=15, batch_size=64)\n",
    "\n",
    "model.save(\"full_model.mnist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "# This line must be executed before loading Keras model.\n",
    "K.set_learning_phase(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'dense_2_1/Softmax:0' shape=(?, 10) dtype=float32>]\n",
      "[<tf.Tensor 'conv2d_1_input_1:0' shape=(?, 28, 28, 1) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('mnist.h5')\n",
    "print(model.outputs)\n",
    "# [<tf.Tensor 'dense_2/Softmax:0' shape=(?, 10) dtype=float32>]\n",
    "print(model.inputs)\n",
    "# [<tf.Tensor 'conv2d_1_input:0' shape=(?, 28, 28, 1) dtype=float32>]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 72 variables.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ INFO ]  Froze %d variables.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Converted 72 variables to const ops.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ INFO ]  Converted %d variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "def freeze_session(session, keep_var_names=None, output_names=None, clear_devices=True):\n",
    "    \"\"\"\n",
    "    Freezes the state of a session into a pruned computation graph.\n",
    "\n",
    "    Creates a new computation graph where variable nodes are replaced by\n",
    "    constants taking their current value in the session. The new graph will be\n",
    "    pruned so subgraphs that are not necessary to compute the requested\n",
    "    outputs are removed.\n",
    "    @param session The TensorFlow session to be frozen.\n",
    "    @param keep_var_names A list of variable names that should not be frozen,\n",
    "                          or None to freeze all the variables in the graph.\n",
    "    @param output_names Names of the relevant graph outputs.\n",
    "    @param clear_devices Remove the device directives from the graph for better portability.\n",
    "    @return The frozen graph definition.\n",
    "    \"\"\"\n",
    "    from tensorflow.python.framework.graph_util import convert_variables_to_constants\n",
    "    graph = session.graph\n",
    "    with graph.as_default():\n",
    "        freeze_var_names = list(set(v.op.name for v in tf.global_variables()).difference(keep_var_names or []))\n",
    "        output_names = output_names or []\n",
    "        output_names += [v.op.name for v in tf.global_variables()]\n",
    "        # Graph -> GraphDef ProtoBuf\n",
    "        input_graph_def = graph.as_graph_def()\n",
    "        if clear_devices:\n",
    "            for node in input_graph_def.node:\n",
    "                node.device = \"\"\n",
    "        frozen_graph = convert_variables_to_constants(session, input_graph_def,\n",
    "                                                      output_names, freeze_var_names)\n",
    "        return frozen_graph\n",
    "\n",
    "\n",
    "frozen_graph = freeze_session(K.get_session(),\n",
    "                              output_names=[out.op.name for out in model.outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model\\\\tf_model.pb'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save to ./model/tf_model.pb\n",
    "tf.train.write_graph(frozen_graph, \"model\", \"tf_model.pb\", as_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
